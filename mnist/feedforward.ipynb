{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (8816, 784)\n",
      "Shape of y:  (8816,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#process dataset\n",
    "df = pd.read_csv(\"mnist/train.csv\")\n",
    "binary_df = df.loc[df['label'].isin([0,1])]\n",
    "binary_df['label']\n",
    "\n",
    "X = binary_df.drop('label', axis=1).values\n",
    "y = binary_df['label'].values\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Shape of X: ', X.shape)\n",
    "print('Shape of y: ', y.shape)\n",
    "\n",
    "#normalise the data to 255\n",
    "X_train = X_train / 255\n",
    "# X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'activate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m#initialise model\u001b[39;00m\n\u001b[0;32m     26\u001b[0m model \u001b[39m=\u001b[39m TestNN()\n\u001b[1;32m---> 28\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n",
      "File \u001b[1;32mc:\\Users\\potat\\Documents\\Computing\\kaggle\\mnist\\np_implementations\\deep_nn.py:108\u001b[0m, in \u001b[0;36mBaseNN.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m: \n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m     \u001b[39m#declare A[0]\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     A \u001b[39m=\u001b[39m X\n\u001b[1;32m--> 108\u001b[0m     A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(A)\n\u001b[0;32m    110\u001b[0m     grad_A \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m(y\u001b[39m/\u001b[39mA) \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39my)\u001b[39m/\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mA)\n\u001b[0;32m    112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward(grad_A)\n",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m, in \u001b[0;36mTestNN.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,X):\n\u001b[1;32m---> 13\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1\u001b[39m.\u001b[39;49mforward(X)\n\u001b[0;32m     14\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2\u001b[39m.\u001b[39mforward(X)\n\u001b[0;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\potat\\Documents\\Computing\\kaggle\\mnist\\np_implementations\\layers.py:49\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, prev_A)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mZ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights, prev_A) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n\u001b[0;32m     48\u001b[0m \u001b[39m# activation function\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mZ)\n\u001b[0;32m     51\u001b[0m \u001b[39m# cache for backpropagation\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev_A \u001b[39m=\u001b[39m prev_A\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'activate'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from np_implementations.deep_nn import BaseNN\n",
    "from np_implementations.layers import Linear, Sigmoid\n",
    "\n",
    "\n",
    "class TestNN(BaseNN):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = Linear(4,784)\n",
    "        self.fc2 = Linear(1,4)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = self.fc1.forward(X)\n",
    "        X = self.fc2.forward(X)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def backward(self, grad_A):\n",
    "        grad_A = self.fc2.backward(grad_A)\n",
    "        grad_A = self.fc1.backward(grad_A)\n",
    "        \n",
    "        return grad_A\n",
    "    \n",
    "#initialise model\n",
    "model = TestNN()\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
